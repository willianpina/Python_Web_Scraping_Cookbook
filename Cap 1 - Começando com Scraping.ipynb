{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 align=center>Capítulo 1 - Começando com Scraping</h1>\n",
    "<p align =center><img src=https://miro.medium.com/max/1000/1*75AH4zD0r5CNtO_Zpf_epg.jpeg width=500></p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Capturando dados com BeautifulSoup e Requests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<Response [200]>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.python.org/events/python-events/'\n",
    "\n",
    "# Fazendo o request\n",
    "req = requests.get(url)\n",
    "req"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'<!doctype html>\\n<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\\n<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\\n<!--[if IE 8]>      <h'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capturando o conteúdo\n",
    "req.text[:200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "b'<!doctype html>\\n<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\\n<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\\n<!--[if IE 8]>      <h'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.content[:200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'PyCon UK 2022', 'location': 'Cardiff City Hall, UK', 'time': '16 Sept. – 18 Sept.  2022'}\n",
      "{'name': 'DjangoCon Europe 2022', 'location': 'Porto, Portugal', 'time': '21 Sept. – 25 Sept.  2022'}\n",
      "{'name': 'PyCon Portugal 2022', 'location': 'Porto, Portugal', 'time': '24 Sept. 2022'}\n",
      "{'name': '9th Conference of Scientific Python Latinamerica', 'location': 'Salta, Argentina', 'time': '26 Sept. – 28 Sept.  2022'}\n",
      "{'name': 'PyConEs - Granada', 'location': '', 'time': '30 Sept. – 02 Oct.  2022'}\n",
      "{'name': 'PyCon MEA @ Global DevSlam 2022', 'location': 'Dubai, UAE', 'time': '10 Oct. – 13 Oct.  2022'}\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "events = soup.find('ul', {'class':'list-recent-events'}).findAll('li')\n",
    "for event in events:\n",
    "\tevent_details = dict()\n",
    "\tevent_details['name'] = event.find('h3').find('a').text\n",
    "\tevent_details['location'] = event.find('span', {'class':'event-location'}).text\n",
    "\tevent_details['time'] = event.find('time').text\n",
    "\tprint(event_details)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Capturando os dados com urllib3 e BeatifulSoup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'PyCon UK 2022', 'location': 'Cardiff City Hall, UK', 'time': '16 Sept. – 18 Sept.  2022'}\n",
      "{'name': 'DjangoCon Europe 2022', 'location': 'Porto, Portugal', 'time': '21 Sept. – 25 Sept.  2022'}\n",
      "{'name': 'PyCon Portugal 2022', 'location': 'Porto, Portugal', 'time': '24 Sept. 2022'}\n",
      "{'name': '9th Conference of Scientific Python Latinamerica', 'location': 'Salta, Argentina', 'time': '26 Sept. – 28 Sept.  2022'}\n",
      "{'name': 'PyConEs - Granada', 'location': '', 'time': '30 Sept. – 02 Oct.  2022'}\n",
      "{'name': 'PyCon MEA @ Global DevSlam 2022', 'location': 'Dubai, UAE', 'time': '10 Oct. – 13 Oct.  2022'}\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "# Criando uma Função para capturar\n",
    "\n",
    "def get_upcoming_events(url):\n",
    "\treq = urllib3.PoolManager()\n",
    "\tres = req.request('GET', url)\n",
    "\n",
    "\tsoup = BeautifulSoup(res.data, 'html.parser')\n",
    "\tevents = soup.find('ul', {'class':'list-recent-events'}).findAll('li')\n",
    "\n",
    "\tfor event in events:\n",
    "\t\tevent_details = dict()\n",
    "\t\tevent_details['name'] = event.find('h3').find(\"a\").text\n",
    "\t\tevent_details['location'] = event.find('span', {'class', 'event-location'}).text\n",
    "\t\tevent_details['time'] = event.find('time').text\n",
    "\t\tprint(event_details)\n",
    "\n",
    "get_upcoming_events(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "class PythonEventsSpider(scrapy.Spider):\n",
    "    name = 'pythoneventsspider'\n",
    "    start_urls = ['https://www.python.org/events/python-events/',]\n",
    "    found_events = []\n",
    "\n",
    "    def parse(self, response):\n",
    "        for event in response.xpath('//ul[contains(@class, \"list-recent-events\")]/li'):\n",
    "            event_details = dict()\n",
    "            event_details['name'] = event.xpath('h3[@class=\"event-title\"]/a/text()').get()\n",
    "            event_details['location'] = event.xpath('p/span[@class=\"event-location\"]/text()').get()\n",
    "            event_details['time'] = event.xpath('p/time/text()').get()\n",
    "            self.found_events.append(event_details)\n",
    "        if __name__ == \"__main__\":\n",
    "            process = CrawlerProcess({'LOG_LEVEL': 'ERROR'})\n",
    "            process.crawl(PythonEventsSpider)\n",
    "            spider = next(iter(process.crawlers)).spider\n",
    "            process.start()\n",
    "            for event in spider.found_events:\n",
    "                print(event)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}